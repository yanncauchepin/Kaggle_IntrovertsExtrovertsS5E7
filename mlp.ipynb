{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d5347a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission_path = \"/kaggle/input/playground-series-s5e7/sample_submission.csv\"\n",
    "train_path = \"/kaggle/input/playground-series-s5e7/train.csv\"\n",
    "test_path = \"/kaggle/input/playground-series-s5e7/test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6095408b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission_path = \"/home/yanncauchepin/Datasets/SupervisedLearning/kaggle_introvertsextroverts/sample_submission.csv\"\n",
    "train_path = \"/home/yanncauchepin/Datasets/SupervisedLearning/kaggle_introvertsextroverts/train.csv\"\n",
    "test_path = \"/home/yanncauchepin/Datasets/SupervisedLearning/kaggle_introvertsextroverts/test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f46beb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "066b397e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_df = pd.read_csv(train_path)\n",
    "test_df = pd.read_csv(test_path)\n",
    "sample_submission_df = pd.read_csv(sample_submission_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5ba470a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Time_spent_Alone</th>\n",
       "      <th>Stage_fear</th>\n",
       "      <th>Social_event_attendance</th>\n",
       "      <th>Going_outside</th>\n",
       "      <th>Drained_after_socializing</th>\n",
       "      <th>Friends_circle_size</th>\n",
       "      <th>Post_frequency</th>\n",
       "      <th>Personality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>No</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Extrovert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>No</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>No</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Extrovert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Introvert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>No</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>No</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Extrovert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>No</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>No</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Extrovert</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  Time_spent_Alone Stage_fear  Social_event_attendance  Going_outside  \\\n",
       "0   0               0.0         No                      6.0            4.0   \n",
       "1   1               1.0         No                      7.0            3.0   \n",
       "2   2               6.0        Yes                      1.0            0.0   \n",
       "3   3               3.0         No                      7.0            3.0   \n",
       "4   4               1.0         No                      4.0            4.0   \n",
       "\n",
       "  Drained_after_socializing  Friends_circle_size  Post_frequency Personality  \n",
       "0                        No                 15.0             5.0   Extrovert  \n",
       "1                        No                 10.0             8.0   Extrovert  \n",
       "2                       NaN                  3.0             0.0   Introvert  \n",
       "3                        No                 11.0             5.0   Extrovert  \n",
       "4                        No                 13.0             NaN   Extrovert  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "447dd70c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                              0\n",
       "Time_spent_Alone             1190\n",
       "Stage_fear                   1893\n",
       "Social_event_attendance      1180\n",
       "Going_outside                1466\n",
       "Drained_after_socializing    1149\n",
       "Friends_circle_size          1054\n",
       "Post_frequency               1264\n",
       "Personality                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "45624e2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                             0\n",
       "Time_spent_Alone             425\n",
       "Stage_fear                   598\n",
       "Social_event_attendance      397\n",
       "Going_outside                466\n",
       "Drained_after_socializing    432\n",
       "Friends_circle_size          350\n",
       "Post_frequency               408\n",
       "dtype: int64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7d8c7d89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.api.types.is_numeric_dtype(train_df[\"Personality\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae86b7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "def impute_nan_non_numeric(df):\n",
    "    for col in df.columns:\n",
    "        if df[col].isnull().any():\n",
    "            if not pd.api.types.is_numeric_dtype(df[col]):\n",
    "                   # For non-numeric columns, use mode imputation\n",
    "                df[col] = df[col].fillna(df[col].mode()[0])\n",
    "                \n",
    "def impute_nan_numeric(df):\n",
    "    for col in df.columns:\n",
    "        if df[col].isnull().any():\n",
    "            if pd.api.types.is_numeric_dtype(df[col]):\n",
    "                print(f\"Imputing missing values in column: {col}\")\n",
    "                missing_mask = df[col].isnull()\n",
    "                df_complete = df[~missing_mask]\n",
    "                df_incomplete = df[missing_mask]\n",
    "                if df_complete.empty:\n",
    "                    imputer = SimpleImputer(strategy='mean')\n",
    "                    df[col] = imputer.fit_transform(df[[col]])\n",
    "                    continue\n",
    "                X_complete = df_complete.drop(col, axis=1, errors='ignore')  # Drop target, handle missing columns\n",
    "                y_complete = df_complete[col]\n",
    "                X_incomplete = df_incomplete.drop(col, axis=1, errors='ignore') # Drop target, handle missing columns\n",
    "\n",
    "                # Handle missing values in features using SimpleImputer (before model training)\n",
    "                # num_imputer = SimpleImputer(strategy='median')  # Or use 'mean', 'most_frequent', 'constant'\n",
    "                # X_complete = num_imputer.fit_transform(X_complete)\n",
    "                # X_incomplete = num_imputer.transform(X_incomplete)\n",
    "\n",
    "                # Train the RandomForestRegressor model\n",
    "                print(f\"{X_incomplete} - {X_complete}\")\n",
    "                model = RandomForestRegressor(n_estimators=100, random_state=42)  # Adjust hyperparameters as needed\n",
    "                model.fit(X_complete, y_complete)\n",
    "\n",
    "                # Predict the missing values\n",
    "                predicted_values = model.predict(X_incomplete)\n",
    "\n",
    "                # Fill the missing values in the original DataFrame\n",
    "                df.loc[missing_mask, col] = predicted_values\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "90f8537e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Time_spent_Alone</th>\n",
       "      <th>Social_event_attendance</th>\n",
       "      <th>Going_outside</th>\n",
       "      <th>Friends_circle_size</th>\n",
       "      <th>Post_frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>18524.000000</td>\n",
       "      <td>17334.000000</td>\n",
       "      <td>17344.000000</td>\n",
       "      <td>17058.000000</td>\n",
       "      <td>17470.000000</td>\n",
       "      <td>17260.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>9261.500000</td>\n",
       "      <td>3.137764</td>\n",
       "      <td>5.265106</td>\n",
       "      <td>4.044319</td>\n",
       "      <td>7.996737</td>\n",
       "      <td>4.982097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5347.562529</td>\n",
       "      <td>3.003786</td>\n",
       "      <td>2.753359</td>\n",
       "      <td>2.062580</td>\n",
       "      <td>4.223484</td>\n",
       "      <td>2.879139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4630.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9261.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>13892.250000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>18523.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id  Time_spent_Alone  Social_event_attendance  Going_outside  \\\n",
       "count  18524.000000      17334.000000             17344.000000   17058.000000   \n",
       "mean    9261.500000          3.137764                 5.265106       4.044319   \n",
       "std     5347.562529          3.003786                 2.753359       2.062580   \n",
       "min        0.000000          0.000000                 0.000000       0.000000   \n",
       "25%     4630.750000          1.000000                 3.000000       3.000000   \n",
       "50%     9261.500000          2.000000                 5.000000       4.000000   \n",
       "75%    13892.250000          4.000000                 8.000000       6.000000   \n",
       "max    18523.000000         11.000000                10.000000       7.000000   \n",
       "\n",
       "       Friends_circle_size  Post_frequency  \n",
       "count         17470.000000    17260.000000  \n",
       "mean              7.996737        4.982097  \n",
       "std               4.223484        2.879139  \n",
       "min               0.000000        0.000000  \n",
       "25%               5.000000        3.000000  \n",
       "50%               8.000000        5.000000  \n",
       "75%              12.000000        7.000000  \n",
       "max              15.000000       10.000000  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "db53c31d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Time_spent_Alone</th>\n",
       "      <th>Social_event_attendance</th>\n",
       "      <th>Going_outside</th>\n",
       "      <th>Friends_circle_size</th>\n",
       "      <th>Post_frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6175.000000</td>\n",
       "      <td>5750.000000</td>\n",
       "      <td>5778.000000</td>\n",
       "      <td>5709.000000</td>\n",
       "      <td>5825.000000</td>\n",
       "      <td>5767.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>21611.000000</td>\n",
       "      <td>3.116870</td>\n",
       "      <td>5.287989</td>\n",
       "      <td>4.037835</td>\n",
       "      <td>8.008412</td>\n",
       "      <td>5.028958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1782.713288</td>\n",
       "      <td>2.985658</td>\n",
       "      <td>2.758052</td>\n",
       "      <td>2.045207</td>\n",
       "      <td>4.192701</td>\n",
       "      <td>2.867285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>18524.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>20067.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>21611.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>23154.500000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>24698.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id  Time_spent_Alone  Social_event_attendance  Going_outside  \\\n",
       "count   6175.000000       5750.000000              5778.000000    5709.000000   \n",
       "mean   21611.000000          3.116870                 5.287989       4.037835   \n",
       "std     1782.713288          2.985658                 2.758052       2.045207   \n",
       "min    18524.000000          0.000000                 0.000000       0.000000   \n",
       "25%    20067.500000          1.000000                 3.000000       3.000000   \n",
       "50%    21611.000000          2.000000                 5.000000       4.000000   \n",
       "75%    23154.500000          4.000000                 8.000000       6.000000   \n",
       "max    24698.000000         11.000000                10.000000       7.000000   \n",
       "\n",
       "       Friends_circle_size  Post_frequency  \n",
       "count          5825.000000     5767.000000  \n",
       "mean              8.008412        5.028958  \n",
       "std               4.192701        2.867285  \n",
       "min               0.000000        0.000000  \n",
       "25%               5.000000        3.000000  \n",
       "50%               8.000000        5.000000  \n",
       "75%              12.000000        7.000000  \n",
       "max              15.000000       10.000000  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "053d5e49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                             int64\n",
       "Time_spent_Alone             float64\n",
       "Stage_fear                    object\n",
       "Social_event_attendance      float64\n",
       "Going_outside                float64\n",
       "Drained_after_socializing     object\n",
       "Friends_circle_size          float64\n",
       "Post_frequency               float64\n",
       "Personality                   object\n",
       "dtype: object"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5c4381fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                             int64\n",
       "Time_spent_Alone             float64\n",
       "Stage_fear                    object\n",
       "Social_event_attendance      float64\n",
       "Going_outside                float64\n",
       "Drained_after_socializing     object\n",
       "Friends_circle_size          float64\n",
       "Post_frequency               float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "45dd679b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df, label_encoders=None):\n",
    "    \n",
    "    df = impute_nan(df)\n",
    "    \n",
    "    if label_encoders is None:\n",
    "        label_encoders = {}\n",
    "    \n",
    "    for col in df.select_dtypes(include=['object']).columns:\n",
    "        if col in label_encoders:\n",
    "            le = label_encoders[col]\n",
    "            df[col] = le.transform(df[col])\n",
    "        else:\n",
    "            le = LabelEncoder()\n",
    "            df[col] = le.fit_transform(df[col])\n",
    "            label_encoders[col] = le\n",
    "    \n",
    "    return df, label_encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "70440b40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputing missing values in column: Time_spent_Alone\n",
      "          id Stage_fear  Social_event_attendance  Going_outside  \\\n",
      "15        15         No                      7.0            6.0   \n",
      "29        29        Yes                      1.0            0.0   \n",
      "31        31         No                      4.0            NaN   \n",
      "41        41         No                      6.0            5.0   \n",
      "62        62         No                      6.0            6.0   \n",
      "...      ...        ...                      ...            ...   \n",
      "18502  18502         No                      4.0            5.0   \n",
      "18510  18510         No                      NaN            5.0   \n",
      "18515  18515         No                      9.0            4.0   \n",
      "18516  18516         No                      6.0            5.0   \n",
      "18522  18522        Yes                      1.0            0.0   \n",
      "\n",
      "      Drained_after_socializing  Friends_circle_size  Post_frequency  \\\n",
      "15                           No                  5.0             8.0   \n",
      "29                          Yes                  4.0             0.0   \n",
      "31                           No                 11.0             5.0   \n",
      "41                           No                 14.0             3.0   \n",
      "62                           No                 13.0             4.0   \n",
      "...                         ...                  ...             ...   \n",
      "18502                        No                 15.0             6.0   \n",
      "18510                        No                 12.0             9.0   \n",
      "18515                        No                  5.0             8.0   \n",
      "18516                        No                  9.0             4.0   \n",
      "18522                       Yes                  5.0             2.0   \n",
      "\n",
      "      Personality  \n",
      "15      Extrovert  \n",
      "29      Introvert  \n",
      "31      Extrovert  \n",
      "41      Extrovert  \n",
      "62      Extrovert  \n",
      "...           ...  \n",
      "18502   Extrovert  \n",
      "18510   Extrovert  \n",
      "18515   Extrovert  \n",
      "18516   Extrovert  \n",
      "18522   Introvert  \n",
      "\n",
      "[1190 rows x 8 columns] -           id Stage_fear  Social_event_attendance  Going_outside  \\\n",
      "0          0         No                      6.0            4.0   \n",
      "1          1         No                      7.0            3.0   \n",
      "2          2        Yes                      1.0            0.0   \n",
      "3          3         No                      7.0            3.0   \n",
      "4          4         No                      4.0            4.0   \n",
      "...      ...        ...                      ...            ...   \n",
      "18518  18518         No                      8.0            3.0   \n",
      "18519  18519         No                      7.0            3.0   \n",
      "18520  18520         No                      6.0            7.0   \n",
      "18521  18521        Yes                      1.0            1.0   \n",
      "18523  18523         No                      8.0            6.0   \n",
      "\n",
      "      Drained_after_socializing  Friends_circle_size  Post_frequency  \\\n",
      "0                            No                 15.0             5.0   \n",
      "1                            No                 10.0             8.0   \n",
      "2                            No                  3.0             0.0   \n",
      "3                            No                 11.0             5.0   \n",
      "4                            No                 13.0             NaN   \n",
      "...                         ...                  ...             ...   \n",
      "18518                        No                  5.0             8.0   \n",
      "18519                        No                  9.0             7.0   \n",
      "18520                        No                  6.0             5.0   \n",
      "18521                       Yes                  1.0             NaN   \n",
      "18523                        No                  4.0             7.0   \n",
      "\n",
      "      Personality  \n",
      "0       Extrovert  \n",
      "1       Extrovert  \n",
      "2       Introvert  \n",
      "3       Extrovert  \n",
      "4       Extrovert  \n",
      "...           ...  \n",
      "18518   Extrovert  \n",
      "18519   Extrovert  \n",
      "18520   Extrovert  \n",
      "18521   Introvert  \n",
      "18523   Extrovert  \n",
      "\n",
      "[17334 rows x 8 columns]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'No'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[32m/tmp/ipykernel_63974/3542629979.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m preprocessed_train_df, label_encoders = preprocess_data(train_df)\n\u001b[32m      2\u001b[39m preprocessed_test_df, _ = preprocess_data(test_df, label_encoders)\n",
      "\u001b[32m/tmp/ipykernel_63974/1560733048.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(df, label_encoders)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m preprocess_data(df, label_encoders=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m      2\u001b[39m \n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     df = impute_nan(df)\n\u001b[32m      4\u001b[39m \n\u001b[32m      5\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m label_encoders \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m      6\u001b[39m         label_encoders = {}\n",
      "\u001b[32m/tmp/ipykernel_63974/2447175687.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(df)\u001b[39m\n\u001b[32m     29\u001b[39m \n\u001b[32m     30\u001b[39m                 \u001b[38;5;66;03m# Train the RandomForestRegressor model\u001b[39;00m\n\u001b[32m     31\u001b[39m                 print(f\"{X_incomplete} - {X_complete}\")\n\u001b[32m     32\u001b[39m                 model = RandomForestRegressor(n_estimators=\u001b[32m100\u001b[39m, random_state=\u001b[32m42\u001b[39m)  \u001b[38;5;66;03m# Adjust hyperparameters as needed\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m                 model.fit(X_complete, y_complete)\n\u001b[32m     34\u001b[39m \n\u001b[32m     35\u001b[39m                 \u001b[38;5;66;03m# Predict the missing values\u001b[39;00m\n\u001b[32m     36\u001b[39m                 predicted_values = model.predict(X_incomplete)\n",
      "\u001b[32m~/Code/.venv/lib/python3.12/site-packages/sklearn/base.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1469\u001b[39m                 skip_parameter_validation=(\n\u001b[32m   1470\u001b[39m                     prefer_skip_nested_validation \u001b[38;5;28;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1471\u001b[39m                 )\n\u001b[32m   1472\u001b[39m             ):\n\u001b[32m-> \u001b[39m\u001b[32m1473\u001b[39m                 \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, *args, **kwargs)\n",
      "\u001b[32m~/Code/.venv/lib/python3.12/site-packages/sklearn/ensemble/_forest.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m    359\u001b[39m         \u001b[38;5;66;03m# Validate or convert input data\u001b[39;00m\n\u001b[32m    360\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m issparse(y):\n\u001b[32m    361\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m ValueError(\u001b[33m\"sparse multilabel-indicator for y is not supported.\"\u001b[39m)\n\u001b[32m    362\u001b[39m \n\u001b[32m--> \u001b[39m\u001b[32m363\u001b[39m         X, y = self._validate_data(\n\u001b[32m    364\u001b[39m             X,\n\u001b[32m    365\u001b[39m             y,\n\u001b[32m    366\u001b[39m             multi_output=\u001b[38;5;28;01mTrue\u001b[39;00m,\n",
      "\u001b[32m~/Code/.venv/lib/python3.12/site-packages/sklearn/base.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[39m\n\u001b[32m    646\u001b[39m                 \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"estimator\"\u001b[39m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01min\u001b[39;00m check_y_params:\n\u001b[32m    647\u001b[39m                     check_y_params = {**default_check_params, **check_y_params}\n\u001b[32m    648\u001b[39m                 y = check_array(y, input_name=\u001b[33m\"y\"\u001b[39m, **check_y_params)\n\u001b[32m    649\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m650\u001b[39m                 X, y = check_X_y(X, y, **check_params)\n\u001b[32m    651\u001b[39m             out = X, y\n\u001b[32m    652\u001b[39m \n\u001b[32m    653\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m no_val_X \u001b[38;5;28;01mand\u001b[39;00m check_params.get(\u001b[33m\"ensure_2d\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "\u001b[32m~/Code/.venv/lib/python3.12/site-packages/sklearn/utils/validation.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[39m\n\u001b[32m   1297\u001b[39m         raise ValueError(\n\u001b[32m   1298\u001b[39m             f\"{estimator_name} requires y to be passed, but the target y is None\"\n\u001b[32m   1299\u001b[39m         )\n\u001b[32m   1300\u001b[39m \n\u001b[32m-> \u001b[39m\u001b[32m1301\u001b[39m     X = check_array(\n\u001b[32m   1302\u001b[39m         X,\n\u001b[32m   1303\u001b[39m         accept_sparse=accept_sparse,\n\u001b[32m   1304\u001b[39m         accept_large_sparse=accept_large_sparse,\n",
      "\u001b[32m~/Code/.venv/lib/python3.12/site-packages/sklearn/utils/validation.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[39m\n\u001b[32m   1009\u001b[39m                         )\n\u001b[32m   1010\u001b[39m                     array = xp.astype(array, dtype, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m   1011\u001b[39m                 \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1012\u001b[39m                     array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n\u001b[32m-> \u001b[39m\u001b[32m1013\u001b[39m             \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[32m   1014\u001b[39m                 raise ValueError(\n\u001b[32m   1015\u001b[39m                     \u001b[33m\"Complex data not supported\\n{}\\n\"\u001b[39m.format(array)\n\u001b[32m   1016\u001b[39m                 ) \u001b[38;5;28;01mfrom\u001b[39;00m complex_warning\n",
      "\u001b[32m~/Code/.venv/lib/python3.12/site-packages/sklearn/utils/_array_api.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(array, dtype, order, copy, xp, device)\u001b[39m\n\u001b[32m    741\u001b[39m         \u001b[38;5;66;03m# Use NumPy API to support order\u001b[39;00m\n\u001b[32m    742\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    743\u001b[39m             array = numpy.array(array, order=order, dtype=dtype)\n\u001b[32m    744\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m745\u001b[39m             array = numpy.asarray(array, order=order, dtype=dtype)\n\u001b[32m    746\u001b[39m \n\u001b[32m    747\u001b[39m         \u001b[38;5;66;03m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[32m    748\u001b[39m         \u001b[38;5;66;03m# container that is consistent with the input's namespace.\u001b[39;00m\n",
      "\u001b[32m~/Code/.venv/lib/python3.12/site-packages/pandas/core/generic.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, dtype, copy)\u001b[39m\n\u001b[32m   2149\u001b[39m     def __array__(\n\u001b[32m   2150\u001b[39m         self, dtype: npt.DTypeLike | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m, copy: bool_t | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   2151\u001b[39m     ) -> np.ndarray:\n\u001b[32m   2152\u001b[39m         values = self._values\n\u001b[32m-> \u001b[39m\u001b[32m2153\u001b[39m         arr = np.asarray(values, dtype=dtype)\n\u001b[32m   2154\u001b[39m         if (\n\u001b[32m   2155\u001b[39m             astype_is_view(values.dtype, arr.dtype)\n\u001b[32m   2156\u001b[39m             \u001b[38;5;28;01mand\u001b[39;00m using_copy_on_write()\n",
      "\u001b[31mValueError\u001b[39m: could not convert string to float: 'No'"
     ]
    }
   ],
   "source": [
    "preprocessed_train_df, label_encoders = preprocess_data(train_df)\n",
    "preprocessed_test_df, _ = preprocess_data(test_df, label_encoders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "e127adc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time_spent_Alone\n",
       "0.0     3139\n",
       "3.0     3081\n",
       "2.0     3039\n",
       "1.0     2973\n",
       "4.0     1079\n",
       "5.0      633\n",
       "10.0     587\n",
       "8.0      582\n",
       "7.0      581\n",
       "6.0      574\n",
       "9.0      574\n",
       "11.0     492\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"Time_spent_Alone\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1958219",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, dropout_rate=0.0):\n",
    "        super(MLP, self).__init__()\n",
    "        self.layers = nn.Sequential()\n",
    "\n",
    "        # Input layer\n",
    "        self.layers.add_module('fc1', nn.Linear(input_size, hidden_size[0]))\n",
    "        self.layers.add_module('relu1', nn.ReLU())\n",
    "        if dropout_rate > 0:\n",
    "            self.layers.add_module('dropout1', nn.Dropout(dropout_rate))\n",
    "\n",
    "        # Hidden layers\n",
    "        for i in range(len(hidden_size) - 1):\n",
    "            self.layers.add_module(f'fc{i+2}', nn.Linear(hidden_size[i], hidden_size[i + 1]))\n",
    "            self.layers.add_module(f'relu{i+2}', nn.ReLU())\n",
    "            if dropout_rate > 0:\n",
    "                self.layers.add_module(f'dropout{i+2}', nn.Dropout(dropout_rate))\n",
    "\n",
    "        # Output layer\n",
    "        self.layers.add_module('output', nn.Linear(hidden_size[-1], output_size))\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df33d53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "input_size = preprocessed_train_df.shape[1] - 1 \n",
    "output_size = 1  \n",
    "hidden_size = [32, 64, 64, 32] \n",
    "dropout_rate = 0.2\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = MLP(input_size, hidden_size, output_size, dropout_rate).to(device)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "X = preprocessed_train_df.drop(columns=['Personality']).values\n",
    "Y = preprocessed_train_df['Personality'].values\n",
    "X_test = preprocessed_test_df.values\n",
    "\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.15, random_state=42)\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
    "Y_train_tensor = torch.tensor(Y_train, dtype=torch.float32).to(device).view(-1, 1)\n",
    "X_val_tensor = torch.tensor(X_val, dtype=torch.float32).to(device)\n",
    "Y_val_tensor = torch.tensor(Y_val, dtype=torch.float32).to(device).view(-1, 1)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
    "\n",
    "num_epochs = 200\n",
    "batch_size = 32\n",
    "train_dataset = torch.utils.data.TensorDataset(X_train_tensor, Y_train_tensor)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4cbc27d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.7355, Validation Loss: 0.6323\n",
      "Validation Accuracy: 0.7355, Validation Loss: 0.5891\n",
      "Validation Accuracy: 0.7355, Validation Loss: 0.5932\n",
      "Validation Accuracy: 0.7355, Validation Loss: 0.5793\n",
      "Validation Accuracy: 0.7355, Validation Loss: 0.5790\n",
      "Validation Accuracy: 0.7355, Validation Loss: 0.5779\n",
      "Validation Accuracy: 0.7355, Validation Loss: 0.5777\n",
      "Validation Accuracy: 0.7355, Validation Loss: 0.5777\n",
      "Validation Accuracy: 0.7355, Validation Loss: 0.5777\n",
      "Epoch [10/200], Loss: 0.5729\n",
      "Validation Accuracy: 0.7355, Validation Loss: 0.5777\n",
      "Validation Accuracy: 0.7355, Validation Loss: 0.5770\n",
      "Validation Accuracy: 0.7355, Validation Loss: 0.5763\n",
      "Validation Accuracy: 0.7355, Validation Loss: 0.5756\n",
      "Validation Accuracy: 0.7355, Validation Loss: 0.5761\n",
      "Validation Accuracy: 0.7355, Validation Loss: 0.5755\n",
      "Validation Accuracy: 0.7355, Validation Loss: 0.5739\n",
      "Validation Accuracy: 0.7355, Validation Loss: 0.5747\n",
      "Validation Accuracy: 0.7355, Validation Loss: 0.5736\n",
      "Validation Accuracy: 0.7355, Validation Loss: 0.5681\n",
      "Epoch [20/200], Loss: 0.5640\n",
      "Validation Accuracy: 0.7355, Validation Loss: 0.5704\n",
      "Validation Accuracy: 0.7355, Validation Loss: 0.5640\n",
      "Validation Accuracy: 0.7355, Validation Loss: 0.4582\n",
      "Validation Accuracy: 0.7355, Validation Loss: 0.3555\n",
      "Validation Accuracy: 0.9662, Validation Loss: 0.1976\n",
      "Validation Accuracy: 0.9669, Validation Loss: 0.1812\n",
      "Validation Accuracy: 0.9669, Validation Loss: 0.1685\n",
      "Validation Accuracy: 0.9701, Validation Loss: 0.1672\n",
      "Validation Accuracy: 0.9687, Validation Loss: 0.1672\n",
      "Validation Accuracy: 0.9705, Validation Loss: 0.1689\n",
      "Epoch [30/200], Loss: 0.2140\n",
      "Validation Accuracy: 0.9701, Validation Loss: 0.1479\n",
      "Validation Accuracy: 0.9709, Validation Loss: 0.1765\n",
      "Validation Accuracy: 0.9597, Validation Loss: 0.1717\n",
      "Validation Accuracy: 0.9709, Validation Loss: 0.1738\n",
      "Validation Accuracy: 0.9701, Validation Loss: 0.1690\n",
      "Validation Accuracy: 0.9705, Validation Loss: 0.1473\n",
      "Validation Accuracy: 0.9712, Validation Loss: 0.1493\n",
      "Validation Accuracy: 0.9705, Validation Loss: 0.1853\n",
      "Validation Accuracy: 0.9701, Validation Loss: 0.1540\n",
      "Validation Accuracy: 0.9705, Validation Loss: 0.1593\n",
      "Epoch [40/200], Loss: 0.2001\n",
      "Validation Accuracy: 0.9709, Validation Loss: 0.1718\n",
      "Validation Accuracy: 0.9248, Validation Loss: 0.2871\n",
      "Validation Accuracy: 0.9709, Validation Loss: 0.1642\n",
      "Validation Accuracy: 0.9608, Validation Loss: 0.1691\n",
      "Validation Accuracy: 0.9701, Validation Loss: 0.1813\n",
      "Validation Accuracy: 0.9673, Validation Loss: 0.1607\n",
      "Validation Accuracy: 0.9712, Validation Loss: 0.1530\n",
      "Validation Accuracy: 0.9698, Validation Loss: 0.1557\n",
      "Validation Accuracy: 0.9709, Validation Loss: 0.1570\n",
      "Validation Accuracy: 0.9712, Validation Loss: 0.1602\n",
      "Epoch [50/200], Loss: 0.2052\n",
      "Validation Accuracy: 0.9705, Validation Loss: 0.1413\n",
      "Validation Accuracy: 0.9655, Validation Loss: 0.1594\n",
      "Validation Accuracy: 0.9683, Validation Loss: 0.1418\n",
      "Validation Accuracy: 0.9701, Validation Loss: 0.2685\n",
      "Validation Accuracy: 0.9705, Validation Loss: 0.1393\n",
      "Validation Accuracy: 0.9705, Validation Loss: 0.1412\n",
      "Validation Accuracy: 0.9709, Validation Loss: 0.1392\n",
      "Validation Accuracy: 0.9712, Validation Loss: 0.1378\n",
      "Validation Accuracy: 0.9705, Validation Loss: 0.1395\n",
      "Validation Accuracy: 0.9698, Validation Loss: 0.1350\n",
      "Epoch [60/200], Loss: 0.1685\n",
      "Validation Accuracy: 0.9701, Validation Loss: 0.1353\n",
      "Validation Accuracy: 0.9629, Validation Loss: 0.1487\n",
      "Validation Accuracy: 0.9709, Validation Loss: 0.1345\n",
      "Validation Accuracy: 0.9712, Validation Loss: 0.1510\n",
      "Validation Accuracy: 0.9712, Validation Loss: 0.1333\n",
      "Validation Accuracy: 0.9655, Validation Loss: 0.1612\n",
      "Validation Accuracy: 0.9665, Validation Loss: 0.1416\n",
      "Validation Accuracy: 0.9709, Validation Loss: 0.1398\n",
      "Validation Accuracy: 0.9709, Validation Loss: 0.1348\n",
      "Validation Accuracy: 0.9665, Validation Loss: 0.1419\n",
      "Epoch [70/200], Loss: 0.1877\n",
      "Validation Accuracy: 0.9662, Validation Loss: 0.1495\n",
      "Validation Accuracy: 0.9712, Validation Loss: 0.1337\n",
      "Validation Accuracy: 0.9712, Validation Loss: 0.1422\n",
      "Validation Accuracy: 0.9709, Validation Loss: 0.1357\n",
      "Validation Accuracy: 0.9691, Validation Loss: 0.1407\n",
      "Validation Accuracy: 0.9698, Validation Loss: 0.1395\n",
      "Validation Accuracy: 0.9615, Validation Loss: 0.1513\n",
      "Validation Accuracy: 0.9701, Validation Loss: 0.1449\n",
      "Validation Accuracy: 0.9709, Validation Loss: 0.1358\n",
      "Validation Accuracy: 0.9712, Validation Loss: 0.1370\n",
      "Epoch [80/200], Loss: 0.1738\n",
      "Validation Accuracy: 0.9705, Validation Loss: 0.1398\n",
      "Validation Accuracy: 0.9701, Validation Loss: 0.1344\n",
      "Validation Accuracy: 0.9662, Validation Loss: 0.1564\n",
      "Validation Accuracy: 0.9712, Validation Loss: 0.1366\n",
      "Validation Accuracy: 0.9701, Validation Loss: 0.1478\n",
      "Early stopping triggered after 84 epochs!\n"
     ]
    }
   ],
   "source": [
    "patience = 15  # Number of epochs to wait for improvement\n",
    "best_val_loss = float('inf')\n",
    "epochs_no_improve = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {running_loss / len(train_loader):.4f}')\n",
    "        \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_outputs = model(X_val_tensor.to(device)) # Ensure validation data is on the correct device\n",
    "        val_loss = criterion(val_outputs, Y_val_tensor) # Calculate validation loss\n",
    "        val_predictions = torch.sigmoid(val_outputs).cpu().numpy()\n",
    "        val_predictions = (val_predictions > 0.5).astype(int)\n",
    "        accuracy = accuracy_score(Y_val_tensor.cpu().numpy(), val_predictions) # Ensure Y_val is on CPU and is a numpy array\n",
    "        print(f'Validation Accuracy: {accuracy:.4f}, Validation Loss: {val_loss.item():.4f}')\n",
    "\n",
    "        # Early stopping check\n",
    "        if val_loss.item() < best_val_loss:\n",
    "            best_val_loss = val_loss.item()\n",
    "            epochs_no_improve = 0\n",
    "            # Save the best model\n",
    "            torch.save(model.state_dict(), 'mlp_best_model.pth')  # Save the model weights\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            if epochs_no_improve >= patience:\n",
    "                print(f'Early stopping triggered after {epoch + 1} epochs!')\n",
    "                # Load the best model\n",
    "                model.load_state_dict(torch.load('mlp_best_model.pth'))\n",
    "                break\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75abc16a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Personality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18524</td>\n",
       "      <td>Extrovert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18525</td>\n",
       "      <td>Extrovert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18526</td>\n",
       "      <td>Extrovert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18527</td>\n",
       "      <td>Extrovert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18528</td>\n",
       "      <td>Extrovert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6170</th>\n",
       "      <td>24694</td>\n",
       "      <td>Extrovert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6171</th>\n",
       "      <td>24695</td>\n",
       "      <td>Extrovert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6172</th>\n",
       "      <td>24696</td>\n",
       "      <td>Extrovert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6173</th>\n",
       "      <td>24697</td>\n",
       "      <td>Extrovert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6174</th>\n",
       "      <td>24698</td>\n",
       "      <td>Extrovert</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6175 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id Personality\n",
       "0     18524   Extrovert\n",
       "1     18525   Extrovert\n",
       "2     18526   Extrovert\n",
       "3     18527   Extrovert\n",
       "4     18528   Extrovert\n",
       "...     ...         ...\n",
       "6170  24694   Extrovert\n",
       "6171  24695   Extrovert\n",
       "6172  24696   Extrovert\n",
       "6173  24697   Extrovert\n",
       "6174  24698   Extrovert\n",
       "\n",
       "[6175 rows x 2 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5ab00f91",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Personality'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[35]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m     test_predictions = torch.sigmoid(test_outputs).cpu().numpy()\n\u001b[32m      5\u001b[39m     test_predictions = (test_predictions > \u001b[32m0.5\u001b[39m).astype(\u001b[38;5;28mint\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m test_predictions = \u001b[43mlabel_encoders\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mPersonality\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m.inverse_transform(test_predictions.flatten())\n\u001b[32m      9\u001b[39m submission_df = pd.DataFrame({\n\u001b[32m     10\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mid\u001b[39m\u001b[33m'\u001b[39m: test_df[\u001b[33m'\u001b[39m\u001b[33mid\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m     11\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mPersonality\u001b[39m\u001b[33m'\u001b[39m: test_predictions.flatten()\n\u001b[32m     12\u001b[39m })\n\u001b[32m     13\u001b[39m submission_df.to_csv(\u001b[33m'\u001b[39m\u001b[33msubmission.csv\u001b[39m\u001b[33m'\u001b[39m, index=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[31mKeyError\u001b[39m: 'Personality'"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_outputs = model(X_test_tensor)\n",
    "    test_predictions = torch.sigmoid(test_outputs).cpu().numpy()\n",
    "    test_predictions = (test_predictions > 0.5).astype(int)\n",
    "\n",
    "test_predictions = label_encoders['Personality'].inverse_transform(test_predictions.flatten())\n",
    "\n",
    "submission_df = pd.DataFrame({\n",
    "    'id': test_df['id'],\n",
    "    'Personality': test_predictions.flatten()\n",
    "})\n",
    "submission_df.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b19feb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Personality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18524</td>\n",
       "      <td>Extrovert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18525</td>\n",
       "      <td>Introvert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18526</td>\n",
       "      <td>Extrovert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18527</td>\n",
       "      <td>Extrovert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18528</td>\n",
       "      <td>Introvert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6170</th>\n",
       "      <td>24694</td>\n",
       "      <td>Extrovert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6171</th>\n",
       "      <td>24695</td>\n",
       "      <td>Introvert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6172</th>\n",
       "      <td>24696</td>\n",
       "      <td>Extrovert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6173</th>\n",
       "      <td>24697</td>\n",
       "      <td>Extrovert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6174</th>\n",
       "      <td>24698</td>\n",
       "      <td>Introvert</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6175 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Id Personality\n",
       "0     18524   Extrovert\n",
       "1     18525   Introvert\n",
       "2     18526   Extrovert\n",
       "3     18527   Extrovert\n",
       "4     18528   Introvert\n",
       "...     ...         ...\n",
       "6170  24694   Extrovert\n",
       "6171  24695   Introvert\n",
       "6172  24696   Extrovert\n",
       "6173  24697   Extrovert\n",
       "6174  24698   Introvert\n",
       "\n",
       "[6175 rows x 2 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
